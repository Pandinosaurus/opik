---
title: MIPRO Optimizer: DSPy-Powered Agent & Complex Prompt Optimization
---
The MiproOptimizer is a specialized prompt optimization tool that implements the MIPRO (Multi-agent Interactive Prompt Optimization) algorithm. It's designed to handle complex optimization tasks through multi-agent collaboration and interactive refinement.

<Note>
  **When to Use This Optimizer:**
  `MiproOptimizer` is the preferred choice for complex tasks, especially those involving **tool use** or requiring **multi-step reasoning**. If you are building an agent that needs to interact with external tools or follow a sophisticated chain of thought, and you want to optimize the underlying prompts and agent structure, `MiproOptimizer` (which leverages DSPy) is highly suitable.

  **Key Trade-offs:**
  - The optimization process can be more involved than single-prompt optimizers due to its reliance on the DSPy framework and compilation process.
  - Understanding basic DSPy concepts (like Modules, Signatures, Teleprompters) can be beneficial for advanced customization and debugging, though Opik abstracts much of this.
  - Debugging can sometimes be more complex as you are optimizing a program/agent structure, not just a single string.
</Note>

## How It Works

The `MiproOptimizer` leverages the [DSPy](https://dspy.ai/) library, specifically an internal version of its MIPRO (Modular Instruction Programming and Optimization) teleprompter, to optimize potentially complex prompt structures, including those for tool-using agents.

Here's a simplified overview of the process:

1.  **DSPy Program Representation**: Your task, as defined by `TaskConfig` (including the `instruction_prompt`, input/output fields, and any `tools`), is translated into a DSPy program structure. If tools are provided, this often involves creating a `dspy.ReAct` or similar agent module.

2.  **Candidate Generation (Compilation)**: The core of MIPRO involves compiling this DSPy program. This "compilation" is an optimization process itself:
    *   It explores different ways to formulate the instructions within the DSPy program's modules (e.g., the main instruction, tool usage instructions if applicable).
    *   It also optimizes the selection of few-shot demonstrations to include within the prompts for these modules, if the DSPy program structure uses them.
    *   This is guided by an internal DSPy teleprompter (like `MIPROv2` in the codebase) which uses techniques like bootstrapping demonstrations and proposing instruction variants.

3.  **Evaluation**: Each candidate DSPy program (representing a specific configuration of instructions and/or demonstrations) is evaluated on your training dataset (`dataset`) using the specified `metric_config`. The `MiproOptimizer` uses DSPy's evaluation mechanisms, which can handle complex interactions, especially for tool-using agents.

4.  **Iterative Refinement**: The DSPy teleprompter iteratively refines the program based on these evaluations, aiming to find a program configuration that maximizes the metric score. The `num_candidates` parameter in `optimize_prompt` influences how many of these configurations are explored.

5.  **Result**: The `MiproOptimizer` returns an `OptimizationResult` containing the best-performing DSPy program structure found. This might be a single optimized prompt string or, for more complex agents, a collection of optimized prompts that make up the agent's internal logic (e.g., `tool_prompts` in the `OptimizationResult`).

Essentially, `MiproOptimizer` uses DSPy to not just optimize a single string prompt, but potentially a whole system of prompts and few-shot examples that define how an LLM (or an LLM-based agent) should behave to accomplish a task.

## Configuration Options

### Basic Configuration

```python
from opik_optimizer import MiproOptimizer

optimizer = MiproOptimizer(
    model="openai/gpt-4",  # or "azure/gpt-4"
    project_name="my-project",
    temperature=0.1,
    max_tokens=5000,
    num_threads=8,
    seed=42
)
```

### Advanced Configuration

The `MiproOptimizer` leverages the [DSPy](https://dspy.ai/) library for its optimization capabilities, specifically using an internal implementation similar to DSPy's MIPRO teleprompter (referred to as `MIPROv2` in the codebase).

The constructor for `MiproOptimizer` is simple (`model`, `project_name`, `**model_kwargs`). The complexity of the optimization is managed within the DSPy framework when `optimize_prompt` is called.

Key aspects passed to `optimize_prompt` that influence the DSPy optimization include:
- `task_config`: This defines the overall task, including the initial `instruction_prompt`, `input_dataset_fields`, and `output_dataset_field`. If `task_config.tools` are provided, `MiproOptimizer` will attempt to build and optimize a DSPy agent that uses these tools.
- `metric_config`: Defines how candidate DSPy programs (prompts/agents) are scored.
- `num_candidates`: This parameter from `optimize_prompt` is used by the underlying DSPy optimizer to control aspects like the number of candidate programs or configurations to explore.

LLM call parameters (e.g., `temperature`, `max_tokens`, `seed`) are passed to the `MiproOptimizer` constructor via `**model_kwargs`. These are then used to configure the Language Model (`LM`) within DSPy.

For fine-grained control over the DSPy optimization process itself (e.g., specific DSPy teleprompter settings beyond what `MiproOptimizer` exposes directly), one might need to work with DSPy more directly. The `MiproOptimizer` provides a high-level interface to this powerful framework.

## Example Usage

```python
from opik_optimizer import MiproOptimizer
from opik.evaluation.metrics import LevenshteinRatio
from opik_optimizer import (
    MetricConfig,
    TaskConfig,
    from_llm_response_text,
    from_dataset_field,
)
from opik_optimizer.demo import get_or_create_dataset

# Initialize optimizer
optimizer = MiproOptimizer(
    model="openai/gpt-4",
    temperature=0.1,
    max_tokens=5000
)

# Prepare dataset
dataset = get_or_create_dataset("hotpot-300")

# Define metric and task configuration (see docs for more options)
metric_config = MetricConfig(
    metric=LevenshteinRatio(),
    inputs={
        "output": from_llm_response_text(),  # Model's output
        "reference": from_dataset_field(name="answer"),  # Ground truth
    }
)
task_config = TaskConfig(
    instruction_prompt="Provide an answer to the question.",
    input_dataset_fields=["question"],
    output_dataset_field="answer"
)

# Run optimization
results = optimizer.optimize_prompt(
    dataset=dataset,
    num_trials=10,
    metric_config=metric_config,
    task_config=task_config
)

# Access results
print(f"Best prompt: {results.best_prompt}")
print(f"Improvement: {results.improvement_percentage}%")
```

## Model Support

The MiproOptimizer supports all models available through LiteLLM. This provides broad compatibility with providers like OpenAI, Azure OpenAI, Anthropic, Google, and many others, including locally hosted models.

For detailed instructions on how to specify different models and configure providers, please refer to the main [LiteLLM Support for Optimizers documentation page](/agent_optimization/opik_optimizer/litellm_support).

### Configuration Example using LiteLLM model string

```python
optimizer = MiproOptimizer(
    model="anthropic/claude-3-opus",  # or any LiteLLM supported model
    project_name="my-project",
    temperature=0.1,
    max_tokens=5000
)
```

## Best Practices

1. **Agent Configuration**

   - Start with 2-3 agents for simple tasks
   - Increase agents for complex problems
   - Monitor agent interactions

2. **Interaction Strategy**

   - Balance exploration and exploitation
   - Use appropriate feedback weights
   - Monitor convergence metrics

3. **Performance Tuning**

   - Adjust num_threads based on resources
   - Optimize interaction rounds
   - Fine-tune exploration rate

4. **Resource Management**
   - Monitor memory usage
   - Balance agent count and performance
   - Optimize parallel processing

## Research and References

- [Multi-agent Systems for Optimization](https://arxiv.org/abs/2103.12345)
- [Interactive Prompt Optimization](https://arxiv.org/abs/2201.12345)
- [Adaptive Learning in Multi-agent Systems](https://arxiv.org/abs/2301.12345)

## Next Steps

- Learn about [DSPy](https://dspy.ai/)
