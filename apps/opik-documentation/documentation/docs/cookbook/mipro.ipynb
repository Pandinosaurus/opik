{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Agent Optimization with MIPRO\n",
    "\n",
    "MIPRO (Multiprompt Instruction PRoposal Optimizer) is an optimizer you can use to create the best prompts from your task. You can read the original paper [here](https://arxiv.org/abs/2406.11695).\n",
    "\n",
    "This optimizer was popularized by the [DSPy library](https://dspy.ai/) that provided the first and most commonly used implementation.\n",
    "\n",
    "In the notebook below, we will re-implement the algorithm from scratch to get a better understanding of how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization strategy\n",
    "\n",
    "The MIPRO algorithm was developed to optimize the multi-step LLM applications when you don't have labels for each step but rather global label for the entire task. This makes it a great algorithm to automatically optimize agents !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the agent\n",
    "\n",
    "To test the optimization algorithm, we are going to start by creating a very simple agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (1.66.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "%pip install --quiet openai\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = \"Analyze the sentiment of this text and classify it as 'postitive sentiment` or `negative sentiment`. Make sure to use this specific term in the response.\"\n",
    "\n",
    "\n",
    "class SentimentAnalysisTool:\n",
    "    def __init__(self, name: str = \"sentiment\", prompt: str = sentiment_prompt):\n",
    "        self.name = name\n",
    "        self.openai_client = OpenAI()\n",
    "        self.sentiment_prompt = prompt\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.sentiment_prompt},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt = \"Summarize the text provided below.\"\n",
    "\n",
    "\n",
    "class SummarizeTool:\n",
    "    def __init__(self, name: str = \"summarization\", prompt: str = summarize_prompt):\n",
    "        self.name = name\n",
    "        self.openai_client = OpenAI()\n",
    "        self.summarization_prompt = prompt\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.summarization_prompt},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMProgram:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sumarization_tool: SummarizeTool,\n",
    "        sentiment_analysis_tool: SentimentAnalysisTool,\n",
    "    ):\n",
    "        self.name = \"Sentiment Analysis\"\n",
    "        self.sumarization_tool = sumarization_tool\n",
    "        self.sentiment_analysis_tool = sentiment_analysis_tool\n",
    "\n",
    "        self.history = []\n",
    "\n",
    "    def run(self, text: str):\n",
    "        self.history = []\n",
    "\n",
    "        summary = self.sumarization_tool(text)\n",
    "        self.history.append(\n",
    "            {\"name\": self.sumarization_tool.name, \"input\": text, \"output\": summary}\n",
    "        )\n",
    "\n",
    "        sentiment = self.sentiment_analysis_tool(summary)\n",
    "        self.history.append(\n",
    "            {\n",
    "                \"name\": self.sentiment_analysis_tool.name,\n",
    "                \"input\": summary,\n",
    "                \"output\": sentiment,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = LMProgram(SummarizeTool(), SentimentAnalysisTool())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIPRO algorithm relies on the following:\n",
    "1. A dataset: This is a set of labelled data with positive and negative samples\n",
    "2. A metric: A metric to optimize over\n",
    "3. A task: The agent to optimize\n",
    "\n",
    "For the purposes of this investigation, we will define these as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        I just love waiting in long lines at the DMV... said no one ever.\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        The food was absolutely terrible, but at least the waiter was friendly.\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        This movie was so bad that itâ€™s actually hilarious. I had a great time watching it!\"\"\",\n",
    "        \"expected_output\": \"positive sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        Wow, I can't believe how amazing this service is! It only took them two hours to get my order wrong.\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        The software crashes every time I open it. But hey, at least the icon looks nice!\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def equals_metric(output, expected_output):\n",
    "    if expected_output.lower() in output.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review sarcastically expresses dissatisfaction with the long wait times at the DMV, implying a negative sentiment towards the experience of waiting in lines there.\n",
      "1\n",
      "---\n",
      "The customer reviews indicate a negative experience with the food, described as \"absolutely terrible.\" However, they acknowledge a positive aspect of their visit, noting that the waiter was friendly. Overall, the sentiment is more negative due to the dissatisfaction with the food quality.\n",
      "0\n",
      "---\n",
      "The customer review expresses that the movie was poorly made, yet the reviewer found it enjoyable because of its comedic badness. The overall sentiment is positive because the viewer enjoyed the experience despite the movie's low quality.\n",
      "0\n",
      "---\n",
      "The review showcases a sarcastic tone with a negative sentiment. The customer expresses dissatisfaction with the service, highlighting that their order was incorrect despite taking two hours. Overall, the sentiment is negative due to the delay and the error in fulfilling the order.\n",
      "1\n",
      "---\n",
      "The customer's review of the software is primarily negative, as they express frustration that it crashes every time it is opened. However, there is a hint of sarcasm in their comment about the icon looking nice, which doesn't compensate for the software's malfunction. Overall, the sentiment is largely negative due to the software's performance issues despite the brief mention of a positive aspect.\n",
      "0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    res = program.run(i[\"input\"])\n",
    "    print(res)\n",
    "    print(equals_metric(res, i[\"expected_output\"]))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MIPRO algorithm\n",
    "\n",
    "The MIPRO algorithm has 3 phases:\n",
    "1. Initialize\n",
    "\n",
    "### Initialization\n",
    "\n",
    "For the initialization step, we will start by bootstraping a set of N few-shot examples for each module. In the agent defined above, we have three different modules:\n",
    "\n",
    "1. Orchestrator\n",
    "2. Sentiment analysis tool\n",
    "3. Summarization tool\n",
    "\n",
    "For this we are going to use the Bootstrap Demonstration and Grounding.\n",
    "\n",
    "#### Bootstrap demonstrations\n",
    "\n",
    "The concept of bootstrap demonstrations is remarkably simple. The idea is that if the agent as a whole returns the correct output, then we can expect that the input / output pair for each module is correct. This allows us to create a dataset of \"labelled\" data for each module without needing to specify a dataset for each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer review expresses a negative sentiment toward the experience of waiting in long lines at the DMV, using a sarcastic tone to convey dissatisfaction.\n",
      "The customer reviews indicate a negative overall sentiment towards the food, describing it as \"absolutely terrible.\" However, there is a positive mention of the service, as the waiter is described as \"friendly.\"\n",
      "The customer reviews suggest that although the movie was perceived as bad, it was so poorly made that it became unintentionally funny, leading to an enjoyable viewing experience. The overall sentiment appears to be positive, as the reviewer had a great time watching the movie despite its flaws.\n",
      "The customer review contains a sarcastic tone and highlights dissatisfaction with the service. Despite expressing amazement, the comment about getting an order wrong in two hours indicates a negative sentiment towards the experience. Overall, the sentiment of this review is critical and negative.\n",
      "The customer reviews are negative overall. The main issue highlighted is that the software consistently crashes upon opening, indicating significant functionality problems. However, there is a sarcastic compliment regarding the appearance of the software's icon, implying dissatisfaction with the core performance but acknowledging a minor positive in its visual design.\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_demonstrations(program, dataset, metric):\n",
    "    positive_samples = []\n",
    "    for item in dataset:\n",
    "        output = program.run(item[\"input\"])\n",
    "\n",
    "        score = metric(output=output, expected_output=item[\"expected_output\"])\n",
    "\n",
    "        if score >= 1:\n",
    "            positive_samples += program.history\n",
    "\n",
    "    return positive_samples\n",
    "\n",
    "\n",
    "positive_samples = bootstrap_demonstrations(program, dataset, equals_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grounding\n",
    "\n",
    "In order to improve each program, we are going to create some instructions for creating a better prompt that relies on:\n",
    "\n",
    "1. Dataset summary\n",
    "2. Program task\n",
    "3. Prompt tips\n",
    "\n",
    "By relying on this information, we are \"grounding\" the instructions for each modile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To enhance the summarization module of the language model program, it is essential to focus on improving its ability to handle complex linguistic features such as sarcasm, irony, mixed sentiments, and other contextual nuances present in customer reviews. Here are specific instructions to optimize the summarization module:\n",
      "\n",
      "Instruction 1: Enhance Sarcasm Detection\n",
      "- Implement algorithms to identify and interpret sarcastic phrases and irony within reviews, ensuring accurate sentiment reflection despite the sarcasm. This can involve training the model on a larger dataset specifically annotated for sarcasm and irony, or integrating existing NLP techniques specialized in sarcasm detection.\n",
      "\n",
      "Instruction 2: Improve Contextual Understanding\n",
      "- Develop mechanisms for better contextual analysis beyond individual word sentiment. Focus on capturing the overarching tone and intent of the review by understanding not just word sentiment, but also the surrounding context that may affect its meaning. Incorporate components like transformers or attention mechanisms that enable the model to weigh the importance of different parts of the text, thereby improving the relevance and accuracy of summaries.\n",
      "\n",
      "Instruction 3: Address Mixed Sentiments with Aspect-based Analysis\n",
      "- Integrate aspect-based sentiment analysis to separately evaluate and balance contrasting sentiments within a review. For sentences containing both positive and negative elements, the module should be capable of determining which sentiment is more dominant, or recognize the presence of both in the summary. This will help in accurately reflecting the overall viewpoint expressed by the reviewer.\n",
      "\n",
      "Instruction 4: Reinforce Linguistic Pattern Recognition\n",
      "- Bolster the moduleâ€™s ability to recognize and interpret linguistic patterns, such as contrastive conjunctions (\"but,\" \"however\") and sentiment-laden adjectives, that indicate a shift or emphasis in sentiment within the same sentence. This requires expanding the training data with varied examples highlighting these patterns and refining parsing strategies to focus on nuanced syntactic and semantic signals.\n",
      "\n",
      "Instruction 5: Introduce Pragmatic Inference Capabilities\n",
      "- Incorporate pragmatic inference capabilities that allow the summarization model to deduce implicit sentiments or conclusions from the provided text. This can involve adding inference layers that provide context-aware judgment of satisfaction levels based on the tone and narrative style, as indicated by phrases such as \"said no one ever.\"\n",
      "\n",
      "By following these instructions, the summarization module can become more adept at handling the complex and nuanced nature of customer reviews, leading to more accurate and contextually relevant outputs that support the subsequent sentiment analysis.\n",
      "-------\n",
      "To optimize the sentiment analysis module, consider implementing the following instructions:\n",
      "\n",
      "Instruction 1: Enhance the modelâ€™s ability to detect and interpret sarcasm and irony. Develop or integrate advanced techniques that focus on lexical and contextual cues, such as detecting phrases like \"said no one ever,\" which indicate sarcasm. This will improve the accuracy of sentiment classification in texts where sarcasm is used to express negative sentiments.\n",
      "\n",
      "Instruction 2: Implement aspect-based sentiment analysis mechanisms. Equip the model to identify and evaluate different aspects of experiences or products mentioned in a review. This will enable the model to weigh the sentiment expressed in contrasting elements (positive and negative) and determine the overall sentiment more reliably.\n",
      "\n",
      "Instruction 3: Develop a system for prioritizing the dominant sentiment when contrastive conjunctions (like \"but,\" \"however\") are present in the text. Ensure that this component reviews the degree of sentiment expressed in the first and second parts and chooses the conclusion or dominant sentiment factor as a key decision point.\n",
      "\n",
      "Instruction 4: Train the model to better understand humorous contexts, where a negative experience is presented humorously, resulting in an overall positive sentiment. Facilitate this by creating labeled examples explicitly modeled around interpreting humor and its impact on sentiment change.\n",
      "\n",
      "Instruction 5: Refine the modelâ€™s capability to assess pragmatic language use by expanding its context recognition to infer implicit sentiments using language patterns that suggest definitive stances indirectly, such as implied dissatisfaction or satisfaction through humor or exaggerative descriptions.\n",
      "-------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class InstructionGeneration:\n",
    "    def __init__(self, program, dataset, positive_samples):\n",
    "        self.openai_client = OpenAI()\n",
    "        self.program = program\n",
    "        self.dataset = dataset\n",
    "        self.positive_samples = positive_samples\n",
    "\n",
    "    def _get_code(self, name):\n",
    "        for i, cell in enumerate(reversed(In)):  # noqa: F821\n",
    "            if f\"class {name}\" in cell:\n",
    "                return cell\n",
    "\n",
    "        raise ValueError(\"Couldn't find code\")\n",
    "\n",
    "    def summarize_program(self):\n",
    "        code = self._get_code(\"LMProgram\")\n",
    "        prompt = f\"\"\"\n",
    "I need to understand the architecture of a language model program called {self.program.name}.\n",
    "This program code is the following:\n",
    "\n",
    "{code}\n",
    "\n",
    "Please analyze this program structure and provide a concise summary of:\n",
    "1. The overall workflow and how modules connect to each other\n",
    "2. The specific role and responsibility of each module\n",
    "3. How information flows through the program\n",
    "4. Critical dependencies between modules\n",
    "\n",
    "Provide this as a brief, factual summary that would help someone design effective instructions for each module.\n",
    "        \"\"\"\n",
    "\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    def summarize_dataset(self):\n",
    "        prompt = f\"\"\"\n",
    "I need to understand the dataset that provides the input and output of a language model program called {program.name}.\n",
    "The dataset is the following:\n",
    "\n",
    "{json.dumps(self.dataset, indent=2)}\n",
    "\n",
    "Please provide a concise analysis of this dataset focusing on:\n",
    "1. The types of inputs present (patterns, structures, language features)\n",
    "2. The expected outputs and their classification criteria\n",
    "3. Any challenging examples or edge cases (sarcasm, mixed sentiments, etc.)\n",
    "4. Key linguistic patterns that determine the expected output\n",
    "5. What features a model would need to correctly process these examples\n",
    "\n",
    "This analysis should help in designing effective prompts for sentiment analysis that can handle the nuances in this dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    def _generate_instruction_prompt(\n",
    "        self, module_name, program_summary, dataset_summary, positive_samples\n",
    "    ):\n",
    "        return f\"\"\"\n",
    "You are an optimization program that is tasked with creating instructions on how to improve\n",
    "specific parts (called modules) of the LLM program.\n",
    "For this you will be provided with:\n",
    "1. A summary of the program\n",
    "2. A summary of the dataset\n",
    "3. Module examples of positive inputs to the module\n",
    "\n",
    "<Module to Optimize>\n",
    "{module_name}\n",
    "<Module to Optimize>\n",
    "\n",
    "<Program Summary>\n",
    "{program_summary}\n",
    "</Program Summary>\n",
    "\n",
    "<Dataset Summary>\n",
    "{dataset_summary}\n",
    "</Dataset Summary>\n",
    "\n",
    "<Module Examples>\n",
    "{positive_samples}\n",
    "</Module Examples>\n",
    "\n",
    "Return instructions as:\n",
    "Instruction 1: <instruction>\n",
    "Instruction 2: <instruction>\n",
    "        \"\"\"\n",
    "\n",
    "    def generate_instructions(self):\n",
    "        program_summary = self.summarize_program()\n",
    "        dataset_summary = self.summarize_dataset()\n",
    "\n",
    "        # Create instructions for summarization tool:\n",
    "        for module_name in [\"summarization\", \"sentiment\"]:\n",
    "            positive_samples = [\n",
    "                x for x in self.positive_samples if x[\"name\"] == module_name\n",
    "            ]\n",
    "            prompt = self._generate_instruction_prompt(\n",
    "                module_name=module_name,\n",
    "                program_summary=program_summary,\n",
    "                dataset_summary=dataset_summary,\n",
    "                positive_samples=positive_samples,\n",
    "            )\n",
    "\n",
    "            completion = self.openai_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                model=\"gpt-4o\",\n",
    "            )\n",
    "            print(completion.choices[0].message.content)\n",
    "            print(\"-------\")\n",
    "\n",
    "\n",
    "# InstructionGeneration().summarize_program(program)\n",
    "res = InstructionGeneration(\n",
    "    program=program, dataset=dataset, positive_samples=positive_samples\n",
    ").generate_instructions()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_llm_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
