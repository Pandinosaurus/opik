{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Agent Optimization with MIPRO\n",
    "\n",
    "MIPRO (Multiprompt Instruction PRoposal Optimizer) is an optimizer you can use to create the best prompts from your task. You can read the original paper [here](https://arxiv.org/abs/2406.11695).\n",
    "\n",
    "This optimizer was popularized by the [DSPy library](https://dspy.ai/) that provided the first and most commonly used implementation.\n",
    "\n",
    "In the notebook below, we will re-implement the algorithm from scratch to get a better understanding of how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization strategy\n",
    "\n",
    "The MIPRO algorithm was developed to optimize the multi-step LLM applications when you don't have labels for each step but rather global label for the entire task. This makes it a great algorithm to automatically optimize agents !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the agent\n",
    "\n",
    "To test the optimization algorithm, we are going to start by creating a very simple agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (1.66.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "%pip install --quiet openai\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt = \"Analyze the sentiment of this text and classify it as 'postitive sentiment` or `negative sentiment`. Make sure to use this specific term in the response.\"\n",
    "\n",
    "\n",
    "class SentimentAnalysisTool:\n",
    "    def __init__(self, name: str = \"sentiment\", prompt: str = sentiment_prompt):\n",
    "        self.name = name\n",
    "        self.openai_client = OpenAI()\n",
    "        self.sentiment_prompt = prompt\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.sentiment_prompt},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_prompt = \"Summarize the text provided below.\"\n",
    "\n",
    "\n",
    "class SummarizeTool:\n",
    "    def __init__(self, name: str = \"summarization\", prompt: str = summarize_prompt):\n",
    "        self.name = name\n",
    "        self.openai_client = OpenAI()\n",
    "        self.summarization_prompt = prompt\n",
    "\n",
    "    def __call__(self, text: str) -> str:\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.summarization_prompt},\n",
    "                {\"role\": \"user\", \"content\": text},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMProgram:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sumarization_tool: SummarizeTool,\n",
    "        sentiment_analysis_tool: SentimentAnalysisTool,\n",
    "    ):\n",
    "        self.name = \"Sentiment Analysis\"\n",
    "        self.sumarization_tool = sumarization_tool\n",
    "        self.sentiment_analysis_tool = sentiment_analysis_tool\n",
    "\n",
    "        self.history = []\n",
    "\n",
    "    def run(self, text: str):\n",
    "        self.history = []\n",
    "\n",
    "        summary = self.sumarization_tool(text)\n",
    "        self.history.append(\n",
    "            {\"name\": self.sumarization_tool.name, \"input\": text, \"output\": summary}\n",
    "        )\n",
    "\n",
    "        sentiment = self.sentiment_analysis_tool(summary)\n",
    "        self.history.append(\n",
    "            {\n",
    "                \"name\": self.sentiment_analysis_tool.name,\n",
    "                \"input\": summary,\n",
    "                \"output\": sentiment,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = LMProgram(SummarizeTool(), SentimentAnalysisTool())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIPRO algorithm relies on the following:\n",
    "1. A dataset: This is a set of labelled data with positive and negative samples\n",
    "2. A metric: A metric to optimize over\n",
    "3. A task: The agent to optimize\n",
    "\n",
    "For the purposes of this investigation, we will define these as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        I just love waiting in long lines at the DMV... said no one ever.\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        The food was absolutely terrible, but at least the waiter was friendly.\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        This movie was so bad that itâ€™s actually hilarious. I had a great time watching it!\"\"\",\n",
    "        \"expected_output\": \"positive sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        Wow, I can't believe how amazing this service is! It only took them two hours to get my order wrong.\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"\"\"Summarize the following customer reviews and analyze their overall sentiment:\n",
    "        The software crashes every time I open it. But hey, at least the icon looks nice!\"\"\",\n",
    "        \"expected_output\": \"negative sentiment\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "def equals_metric(output, expected_output):\n",
    "    if expected_output.lower() in output.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review sarcastically expresses dissatisfaction with the long wait times at the DMV, implying a negative sentiment towards the experience of waiting in lines there.\n",
      "1\n",
      "---\n",
      "The customer reviews indicate a negative experience with the food, described as \"absolutely terrible.\" However, they acknowledge a positive aspect of their visit, noting that the waiter was friendly. Overall, the sentiment is more negative due to the dissatisfaction with the food quality.\n",
      "0\n",
      "---\n",
      "The customer review expresses that the movie was poorly made, yet the reviewer found it enjoyable because of its comedic badness. The overall sentiment is positive because the viewer enjoyed the experience despite the movie's low quality.\n",
      "0\n",
      "---\n",
      "The review showcases a sarcastic tone with a negative sentiment. The customer expresses dissatisfaction with the service, highlighting that their order was incorrect despite taking two hours. Overall, the sentiment is negative due to the delay and the error in fulfilling the order.\n",
      "1\n",
      "---\n",
      "The customer's review of the software is primarily negative, as they express frustration that it crashes every time it is opened. However, there is a hint of sarcasm in their comment about the icon looking nice, which doesn't compensate for the software's malfunction. Overall, the sentiment is largely negative due to the software's performance issues despite the brief mention of a positive aspect.\n",
      "0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    res = program.run(i[\"input\"])\n",
    "    print(res)\n",
    "    print(equals_metric(res, i[\"expected_output\"]))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MIPRO algorithm\n",
    "\n",
    "The MIPRO algorithm has 3 phases:\n",
    "1. Initialize\n",
    "\n",
    "### Initialization\n",
    "\n",
    "For the initialization step, we will start by bootstraping a set of N few-shot examples for each module. In the agent defined above, we have three different modules:\n",
    "\n",
    "1. Orchestrator\n",
    "2. Sentiment analysis tool\n",
    "3. Summarization tool\n",
    "\n",
    "For this we are going to use the Bootstrap Demonstration and Grounding.\n",
    "\n",
    "#### Bootstrap demonstrations\n",
    "\n",
    "The concept of bootstrap demonstrations is remarkably simple. The idea is that if the agent as a whole returns the correct output, then we can expect that the input / output pair for each module is correct. This allows us to create a dataset of \"labelled\" data for each module without needing to specify a dataset for each module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The customer review expresses a negative sentiment toward the experience of waiting in long lines at the DMV, using a sarcastic tone to convey dissatisfaction.\n",
      "The customer reviews indicate a negative overall sentiment towards the food, describing it as \"absolutely terrible.\" However, there is a positive mention of the service, as the waiter is described as \"friendly.\"\n",
      "The customer reviews suggest that although the movie was perceived as bad, it was so poorly made that it became unintentionally funny, leading to an enjoyable viewing experience. The overall sentiment appears to be positive, as the reviewer had a great time watching the movie despite its flaws.\n",
      "The customer review contains a sarcastic tone and highlights dissatisfaction with the service. Despite expressing amazement, the comment about getting an order wrong in two hours indicates a negative sentiment towards the experience. Overall, the sentiment of this review is critical and negative.\n",
      "The customer reviews are negative overall. The main issue highlighted is that the software consistently crashes upon opening, indicating significant functionality problems. However, there is a sarcastic compliment regarding the appearance of the software's icon, implying dissatisfaction with the core performance but acknowledging a minor positive in its visual design.\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_demonstrations(program, dataset, metric):\n",
    "    positive_samples = []\n",
    "    for item in dataset:\n",
    "        output = program.run(item[\"input\"])\n",
    "        print(output)\n",
    "\n",
    "        score = metric(output=output, expected_output=item[\"expected_output\"])\n",
    "\n",
    "        if score >= 1:\n",
    "            positive_samples += program.history\n",
    "\n",
    "    return positive_samples\n",
    "\n",
    "\n",
    "positive_samples = bootstrap_demonstrations(program, dataset, equals_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grounding\n",
    "\n",
    "In order to improve each program, we are going to create some instructions for creating a better prompt that relies on:\n",
    "\n",
    "1. Dataset summary\n",
    "2. Program task\n",
    "3. Prompt tips\n",
    "\n",
    "By relying on this information, we are \"grounding\" the instructions for each modile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. **Overall Workflow and Module Connections:**\\n   - The `LMProgram` class performs sentiment analysis on a given text by first applying a summarization process.\\n   - The program uses two main components: a summarization tool and a sentiment analysis tool.\\n   - The summarization tool is applied first, and its output is then processed by the sentiment analysis tool.\\n\\n2. **Role and Responsibility of Each Module:**\\n   - **LMProgram:** Acts as the main orchestrator class. It initializes with two tools and processes input text through these tools while maintaining a history of operations.\\n   - **SummarizeTool (summarization_tool):** Presumably tasked with condensing the input text to a shorter form suitable for further analysis. Its exact implementation is abstracted away.\\n   - **SentimentAnalysisTool (sentiment_analysis_tool):** Evaluates the summarized text to determine its sentiment. Details on how it determines sentiment are also abstracted.\\n\\n3. **Information Flow:**\\n   - The program takes raw input text and passes it to the summarization tool.\\n   - The output from the summarization tool is recorded and then fed into the sentiment analysis tool.\\n   - The output of the sentiment analysis is also recorded, and the summarized text is returned as the final output.\\n\\n4. **Critical Dependencies:**\\n   - The program relies on two critical components: the summarization tool and the sentiment analysis tool.\\n   - The summarization tool must generate meaningful summaries; otherwise, the sentiment analysis may be inaccurate.\\n   - The sentiment analysis tool depends on the output from the summarization tool, so any error in summarization will propagate to sentiment analysis.\\n\\nThis summary lays out how the modules interact and depend on each other, highlighting that effective instructions must focus on implementing accurate summarization and sentiment analysis functions.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class InstructionGeneration:\n",
    "    def __init__(self):\n",
    "        self.openai_client = OpenAI()\n",
    "\n",
    "    def _get_code(self, name):\n",
    "        for i, cell in enumerate(reversed(In)):  # noqa: F821\n",
    "            if f\"class {name}\" in cell:\n",
    "                return cell\n",
    "\n",
    "        raise ValueError(\"Couldn't find code\")\n",
    "\n",
    "    def summarize_program(self, program):\n",
    "        code = self._get_code(\"LMProgram\")\n",
    "        prompt = f\"\"\"\n",
    "I need to understand the architecture of a language model program called {program.name}.\n",
    "This program code is the following:\n",
    "\n",
    "{code}\n",
    "\n",
    "Please analyze this program structure and provide a concise summary of:\n",
    "1. The overall workflow and how modules connect to each other\n",
    "2. The specific role and responsibility of each module\n",
    "3. How information flows through the program\n",
    "4. Critical dependencies between modules\n",
    "\n",
    "Provide this as a brief, factual summary that would help someone design effective instructions for each module.\n",
    "        \"\"\"\n",
    "\n",
    "        completion = self.openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            model=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "    def summarize_dataset(self, dataset):\n",
    "        prompt = f\"\"\"\n",
    "I need to understand the dataset that provides the input and output of a language model program called {program.name}.\n",
    "The dataset is the following:\n",
    "\n",
    "{json.dumps(dataset, indent=2)}\n",
    "\n",
    "Please analyze this program structure and provide a concise summary of:\n",
    "1. The overall workflow and how modules connect to each other\n",
    "2. The specific role and responsibility of each module\n",
    "3. How information flows through the program\n",
    "4. Critical dependencies between modules\n",
    "\n",
    "Provide this as a brief, factual summary that would help someone design effective instructions for each module.\n",
    "        \"\"\"\n",
    "\n",
    "        print(prompt)\n",
    "\n",
    "\n",
    "InstructionGeneration().summarize_program(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_llm_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
