{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/comet-ml/opik/blob/main/apps/opik-documentation/documentation/static/img/opik-logo.svg?raw=true\" width=\"200\" height=\"100\" alt=\"Opik Logo\">\n",
        "\n",
        "# Comet Assistant: RAG with Opik with Azure OpenAI\n",
        "\n",
        "The below example walks through the process of building a simple RAG application with OpenAI and langchain, and evaluating the application with Opik.\n",
        "\n",
        "The concepts covered in this tutorial include:\n",
        "\n",
        "1. Setting up a simple vector store and RAG pipeline with langchain\n",
        "2. Defining an assistant application using this RAG pipeline and the OpenAI API\n",
        "3. Creating a dataset of questions for evaluation in Opik\n",
        "4. Automating the evaluation of the application on the dataset using Opik metrics\n",
        "5. Calculate metrics using an Azure OpenAI model"
      ],
      "metadata": {
        "id": "n242nv-d3vfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an account on Comet.com\n",
        "\n",
        "[Comet](https://www.comet.com/site?from=llm&utm_source=opik&utm_medium=colab&utm_content=langchain&utm_campaign=opik) provides a hosted version of the Opik platform, [simply create an account](https://www.comet.com/signup?from=llm&utm_source=opik&utm_medium=colab&utm_content=langchain&utm_campaign=opik) and grab you API Key.\n",
        "\n",
        "> You can also run the Opik platform locally, see the [installation guide](https://www.comet.com/docs/opik/self-host/overview/?from=llm&utm_source=opik&utm_medium=colab&utm_content=langchain&utm_campaign=opik) for more information."
      ],
      "metadata": {
        "id": "G7d_ldIRqSbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet opik openai azure-identity langsmith langchain-community langchain chromadb tiktoken langchain_openai"
      ],
      "metadata": {
        "id": "wybtUdOwmNX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from opik import Opik, track\n",
        "import opik\n",
        "from opik.evaluation import evaluate, models\n",
        "from opik.evaluation.metrics import AnswerRelevance, LevenshteinRatio"
      ],
      "metadata": {
        "id": "TRPCwfT9mlV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opik.configure(use_local=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTuv6r2KmaDU",
        "outputId": "2f3d89eb-728f-4040-ce83-61e459ac73be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPIK: Existing Opik clients will not use updated values for \"url\", \"api_key\", \"workspace\".\n",
            "OPIK: Opik is already configured. You can check the settings by viewing the config file at /root/.opik.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the vector store for RAG"
      ],
      "metadata": {
        "id": "p2pAd1tbqUss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"AZURE_API_BASE\"] = \"https://comet-test-open-ai.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://comet-test-open-ai.openai.azure.com/\"\n",
        "os.environ[\"AZURE_API_VERSION\"] = \"2024-05-01-preview\"\n",
        "\n",
        "if \"AZURE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"AZURE_API_KEY\"] = getpass.getpass(\"Enter your Azure OpenAI API key: \")\n",
        "\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.environ[\"AZURE_API_KEY\"]\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_API_VERSION\"]"
      ],
      "metadata": {
        "id": "JFi5qEgbkIAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up Vector Store and Retriever.**\n",
        "\n",
        "The below code sets up a vector store using [Chroma](https://www.trychroma.com/). Here we are loading Comet SDK reference documentation."
      ],
      "metadata": {
        "id": "nBsNkp9RqvKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as Soup\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "\n",
        "# Load\n",
        "url = \"https://www.comet.com/docs/v2/api-and-sdk/python-sdk/reference/Experiment/\"\n",
        "loader = RecursiveUrlLoader(\n",
        "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
        ")\n",
        "docs = loader.load()\n",
        "\n",
        "# Split\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = splitter.split_documents(docs)\n",
        "\n",
        "# Embed\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=AzureOpenAIEmbeddings(model=\"text-embedding-3-large\"))\n",
        "\n",
        "# Index\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "pCas5t_6bY8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define RAG Application\n",
        "The below code defines our LLM application. In this case, we create a Comet bot that 1) retrieves relevant context from our vector store based on the input 2) inputs the relevant question + user question into OpenAI to retrieve a response.\n",
        "\n",
        "In order to ensure that the OpenAI API calls are being tracked, we will be using the `track_openai` function from the Opik library. We will also use the `track` decorator to ensure each step of the application is tracked."
      ],
      "metadata": {
        "id": "VkN5_LsRq8pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "from opik.integrations.openai import track_openai\n",
        "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
        "\n",
        "# Initialize Azure OpenAI Service client with Entra ID authentication\n",
        "token_provider = get_bearer_token_provider(\n",
        "    DefaultAzureCredential(),\n",
        "    \"https://cognitiveservices.azure.com/.default\"\n",
        ")\n",
        "\n",
        "PROJECT_NAME = \"comet-assistant\"\n",
        "\n",
        "class CometBot:\n",
        "    def __init__(self, retriever, model: str = \"gpt-4o-mini\"):\n",
        "        self._retriever = retriever\n",
        "        self._client = track_openai(AzureOpenAI(), project_name = PROJECT_NAME)\n",
        "        self._model = model\n",
        "\n",
        "    @opik.track(project_name=PROJECT_NAME)\n",
        "    def retrieve_docs(self, question):\n",
        "        return self._retriever.invoke(question)\n",
        "\n",
        "    @opik.track(project_name=PROJECT_NAME)\n",
        "    def get_answer(self, question: str, system: str):\n",
        "        docs_retrieved = self.retrieve_docs(question)\n",
        "        response = self._client.chat.completions.create(\n",
        "            model=self._model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": f\"{system}\"\n",
        "                    \"\\n Use the following docs to produce the answer to the question.\\n\\n\"\"\"\n",
        "                    f\"## Docs\\n\\n{docs_retrieved}\",\n",
        "                },\n",
        "                {\"role\": \"user\", \"content\": question},\n",
        "            ],\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"response\": response.choices[0].message.content,\n",
        "            \"context\": [str(doc) for doc in docs_retrieved],\n",
        "        }\n",
        "\n",
        "\n",
        "rag_bot = CometBot(retriever)"
      ],
      "metadata": {
        "id": "PVYnJcfGkRq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Bot and the Retriever with one system prompt"
      ],
      "metadata": {
        "id": "vURdawlnxOI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a Comet expert. You love explaining Comet concepts. Keep the answers short.\"\n",
        "response = rag_bot.get_answer(\"How can I log a system metric in Comet?\", system_prompt)\n",
        "print(\"Response:\")\n",
        "response[\"response\"]"
      ],
      "metadata": {
        "id": "xxNz6l9JkvR-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "02238fac-f7d9-4299-e571-42587bcbe4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"You can log a system metric in Comet using the `log_system_info` method. Here's a basic example:\\n\\n```python\\nimport comet_ml\\n\\ncomet_ml.login()\\nexp = comet_ml.start()\\n\\nexp.log_system_info(key='metric_name', value='metric_value')\\n\\nexp.end()\\n```\\n\\nReplace `'metric_name'` and `'metric_value'` with your desired key and value.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Dataset: Comet Questions\n",
        "\n",
        "Below we define a standard set of questions that we would like to evaluate the assistant on."
      ],
      "metadata": {
        "id": "5hZmnIk_sRNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_items = [\n",
        "  {\n",
        "    \"question\": \"How do I log a hyperparameter to Comet?\",\n",
        "    \"expected_answer\": \"You can log a hyperparameter to a Comet experiment with the log_parameter() method. Example: experiment.log_parameter('learning-rate', .02) \"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"How do I log a metric to my Comet experiment?\",\n",
        "    \"expected_answer\": \"You can log a hyperparameter to a Comet experiment with the log_metric() method. Example: experiment.log_metric('accuracy', .95)\"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"How do I tag my Comet experiment?\",\n",
        "    \"expected_answer\": \"You can tag your Comet experiment with the add_tag() method. Example: experiment.add_tag('baseline')\"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"How do I rename my Comet experiment?\",\n",
        "    \"expected_answer\": \"You can rename your Comet experiment with the set_name() method. Example: experiment.set_name('experiment-1')\"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"How do I rename my Comet experiment?\",\n",
        "    \"expected_answer\": \"You can rename your Comet experiment with the set_name() method. Example: experiment.set_name('experiment-1')\"\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"How do I use an existing artifact in a new Comet experiment?\",\n",
        "    \"expected_answer\": \"You can use the get_artifact() method to get an existing artifact in a new Comet experiment. Example: experiment.get_artifact('my-artifact', version_or_alias = '1.0.0')\"\n",
        "  }]"
      ],
      "metadata": {
        "id": "SMjfZ8e3sUhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our dataset, we can create a dataset in Opik and insert the questions into it."
      ],
      "metadata": {
        "id": "01ZfKmPKuI9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get or create a dataset\n",
        "client = opik.Opik()\n",
        "\n",
        "dataset = client.get_or_create_dataset(name=\"Comet_Questions\",\n",
        "                                       description=\"Questions about the Comet SDK\")\n",
        "\n",
        "# Inserting will not duplicate entries\n",
        "dataset.insert(dataset_items)"
      ],
      "metadata": {
        "id": "9ZgHuZvxuIdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Assistant\n",
        "\n",
        "In order to ensure our RAG application is working correctly and determine the system prompt to use in production, we will test it on our dataset with 3 different system prompts.\n",
        "\n",
        "For this we will be using the `evaluate` function from the `opik` library. We will evaluate the application on two metrics: Hallucination and AnswerRelevance.\n",
        "\n",
        "**Step 1: Fetch the dataset for evaluation**"
      ],
      "metadata": {
        "id": "hhPzHnXdue0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = opik.Opik()\n",
        "\n",
        "dataset = client.get_dataset(name=\"Comet_Questions\")"
      ],
      "metadata": {
        "id": "s6K4lEdpumWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Define the system prompt to test**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WMTjbCxkup30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = opik.Prompt(\n",
        "    name=\"Comet SDK Assistant - System Prompt\",\n",
        "    prompt=\"\"\"\n",
        "        You are an instructor for technical executives that want to extract value of AI models.\n",
        "        If you know the answer to the question, respond by stating that it is possible to do what is being asked,\n",
        "        but without going into technical details on how to do it.\n",
        "        Make sure you include in your answer:\n",
        "        - A description of the lifecycle of a machine learning model\n",
        "        - Where in this lifecycle the current question is relevant\n",
        "        - The business benefits of implementing the provided answer\n",
        "        - An estimation of the time and cost of implementing the provided answer\n",
        "        \"\"\".rstrip().lstrip()\n",
        ")"
      ],
      "metadata": {
        "id": "1jTeIcWn0bIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Define Evaluation Task**\n",
        "\n",
        "The evaluation task maps each input to the retrieved context and LLM output. These values will be used by Opik when calculating the metrics defined in the next step."
      ],
      "metadata": {
        "id": "HedDKrBLwAtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation_task(x):\n",
        "    full_response = rag_bot.get_answer(x['question'], system_prompt.format())\n",
        "    response = full_response[\"response\"]\n",
        "    context = full_response[\"context\"]\n",
        "    return {\n",
        "        \"response\": response,\n",
        "        \"context\": context\n",
        "    }"
      ],
      "metadata": {
        "id": "YiMwV6G5Hac7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Define Metrics**\n",
        "\n",
        "Here we use Comet's built-in [Levenshtein Ratio](https://www.comet.com/docs/opik/evaluation/metrics/heuristic_metrics#levenshteinratio) and [AnswerRelevance](https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance) metrics. We will use azure/gpt-4o as the model to compute the answer relevance metric\n"
      ],
      "metadata": {
        "id": "C2KYE8QZonMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = models.LiteLLMChatModel(model_name=\"azure/gpt-4o\") # azure endpoint & api version already provided in the environment\n",
        "\n",
        "# Define the metrics\n",
        "answerrelevance_metric = AnswerRelevance(name=\"AnswerRelevance\", model=model)\n",
        "levenshteinratio_metric = LevenshteinRatio(name=\"LevenshteinRatio\")"
      ],
      "metadata": {
        "id": "vHiW5RGHoukC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Run the evaluation**\n",
        "\n",
        "Input the dataset, experiment config, evaluation task, and metrics into Opik's `evaluate` to run the evaluation."
      ],
      "metadata": {
        "id": "myI02oOTwExG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_ID = \"50\"\n",
        "\n",
        "experiment_config = {\"model\": \"gpt-4o-mini\"}\n",
        "experiment_name = f\"comet-assistant-{TEST_ID}\"\n",
        "\n",
        "res = evaluate(\n",
        "    dataset=dataset,\n",
        "    experiment_name=experiment_name,\n",
        "    experiment_config=experiment_config,\n",
        "    project_name=f\"{PROJECT_NAME}-{TEST_ID}\",\n",
        "    task=evaluation_task,\n",
        "    prompt=system_prompt,\n",
        "    scoring_metrics=[answerrelevance_metric,\n",
        "                     levenshteinratio_metric],\n",
        "    scoring_key_mapping={\n",
        "        \"input\": \"question\",\n",
        "        \"output\": \"response\",\n",
        "        \"reference\": \"expected_answer\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "Hv7zEC_AwGyv",
        "outputId": "91aaf571-f961-4333-9f31-a7b8a386d718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]OPIK: Started logging traces to the \"comet-assistant-50\" project at https://www.comet.com/opik/benjtlv/redirect/projects?name=comet-assistant-50.\n",
            "Evaluation: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭─ Comet_Questions (5 samples) ──╮\n",
              "│                                │\n",
              "│ \u001b[1mTotal time:       \u001b[0m 00:00:06    │\n",
              "│ \u001b[1mNumber of samples:\u001b[0m 5           │\n",
              "│                                │\n",
              "│ \u001b[1;32mAnswerRelevance: 0.4500 (avg)\u001b[0m  │\n",
              "│ \u001b[1;32mLevenshteinRatio: 0.1930 (avg)\u001b[0m │\n",
              "│                                │\n",
              "╰────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ Comet_Questions (5 samples) ──╮\n",
              "│                                │\n",
              "│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:06    │\n",
              "│ <span style=\"font-weight: bold\">Number of samples:</span> 5           │\n",
              "│                                │\n",
              "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">AnswerRelevance: 0.4500 (avg)</span>  │\n",
              "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">LevenshteinRatio: 0.1930 (avg)</span> │\n",
              "│                                │\n",
              "╰────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading results to Opik \u001b[33m...\u001b[0m \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "View the results \u001b]8;id=864803;https://www.comet.com/opik/benjtlv/experiments/01956752-e47f-73c8-af7a-fd16cba93ade/compare?experiments=%5B%2201956bee-1316-73cf-9605-f00531510b86%22%5D\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"https://www.comet.com/opik/benjtlv/experiments/01956752-e47f-73c8-af7a-fd16cba93ade/compare?experiments=%5B%2201956bee-1316-73cf-9605-f00531510b86%22%5D\" target=\"_blank\">in your Opik dashboard</a>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nMRbeDTbD_W"
      },
      "source": [
        "The evaluation results are now uploaded to the Opik platform and can be viewed in the UI."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Assistant (II)\n",
        "\n",
        "Prompt Engineering is an iterative process. Let's try a different system prompt."
      ],
      "metadata": {
        "id": "cbOXKd6sDaYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = opik.Prompt(\n",
        "    name=\"Comet SDK Assistant - System Prompt\",\n",
        "    prompt=\"\"\"\n",
        "        You are a Comet expert expert and know how to explain Comet SDK concepts in simple terms.\n",
        "        Keep the answers short and don't try to make up answers that you don't know.\n",
        "        \"\"\".rstrip().lstrip()\n",
        ")"
      ],
      "metadata": {
        "id": "V8zbgPmp3Rem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_ID = \"51\"\n",
        "\n",
        "experiment_config = {\"model\": \"gpt-4o-mini\"}\n",
        "experiment_name = f\"comet-assistant-{TEST_ID}\"\n",
        "\n",
        "res = evaluate(\n",
        "    dataset=dataset,\n",
        "    experiment_name=experiment_name,\n",
        "    experiment_config=experiment_config,\n",
        "    project_name=f\"{PROJECT_NAME}-{TEST_ID}\",\n",
        "    task=evaluation_task,\n",
        "    prompt=system_prompt,\n",
        "    scoring_metrics=[answerrelevance_metric,\n",
        "                     levenshteinratio_metric],\n",
        "    scoring_key_mapping={\n",
        "        \"input\": \"question\",\n",
        "        \"output\": \"response\",\n",
        "        \"reference\": \"expected_answer\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "9pMJQGupE4gY",
        "outputId": "226a724c-80d5-4dfe-c5ad-eba5c5c628dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation:   0%|          | 0/5 [00:00<?, ?it/s]OPIK: Started logging traces to the \"comet-assistant-51\" project at https://www.comet.com/opik/benjtlv/redirect/projects?name=comet-assistant-51.\n",
            "Evaluation: 100%|██████████| 5/5 [00:08<00:00,  1.60s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "╭─ Comet_Questions (5 samples) ──╮\n",
              "│                                │\n",
              "│ \u001b[1mTotal time:       \u001b[0m 00:00:08    │\n",
              "│ \u001b[1mNumber of samples:\u001b[0m 5           │\n",
              "│                                │\n",
              "│ \u001b[1;32mAnswerRelevance: 0.9100 (avg)\u001b[0m  │\n",
              "│ \u001b[1;32mLevenshteinRatio: 0.3686 (avg)\u001b[0m │\n",
              "│                                │\n",
              "╰────────────────────────────────╯\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ Comet_Questions (5 samples) ──╮\n",
              "│                                │\n",
              "│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:08    │\n",
              "│ <span style=\"font-weight: bold\">Number of samples:</span> 5           │\n",
              "│                                │\n",
              "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">AnswerRelevance: 0.9100 (avg)</span>  │\n",
              "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">LevenshteinRatio: 0.3686 (avg)</span> │\n",
              "│                                │\n",
              "╰────────────────────────────────╯\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading results to Opik \u001b[33m...\u001b[0m \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "View the results \u001b]8;id=818209;https://www.comet.com/opik/benjtlv/experiments/01956752-e47f-73c8-af7a-fd16cba93ade/compare?experiments=%5B%2201956be5-1f0e-70fc-9550-b9fa0619126d%22%5D\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"https://www.comet.com/opik/benjtlv/experiments/01956752-e47f-73c8-af7a-fd16cba93ade/compare?experiments=%5B%2201956be5-1f0e-70fc-9550-b9fa0619126d%22%5D\" target=\"_blank\">in your Opik dashboard</a>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py312_llm_eval",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}